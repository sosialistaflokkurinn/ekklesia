# PR #28 Complete Review by √Åg√∫st - All 23 Comments & Action Items

**PR Title**: feat: Firebase Members authentication and Events service design
**PR Number**: #28
**Reviewer**: @agustka (√Åg√∫st K√°rason)
**Review Date**: October 10, 2025 06:53 UTC
**Status**: ‚úÖ APPROVED
**Total Comments**: 23 detailed inline comments + 1 overall approval

---

## Overall Approval ‚úÖ

**Status**: ‚úÖ **APPROVED**

**Original (Icelandic)**:
> L√≠tur vel √∫t, vel skjala√∞ og spennandi a√∞ √æetta skuli vera komi√∞ √° √æennan sta√∞

**Translation (English)**:
> "Looks good, well documented and exciting that this has come this far"

**Analysis**:
- ‚úÖ **"L√≠tur vel √∫t"** (Looks good) - Overall implementation quality approved
- ‚úÖ **"vel skjala√∞"** (well documented) - Documentation quality praised
- ‚úÖ **"spennandi"** (exciting) - Enthusiasm for project progress

---

## Quick Action Summary

### üî¥ Critical (Must Fix Before Production) - 4 items
1. **Race condition on user creation** (Comment 2.10) - Implement idempotency
2. **Firestore security rules** (Comment 2.4) - Users can't read others' profiles
3. **Rate limiting** (Comments 2.16, 2.17) - DDoS protection
4. **CSRF protection** (Comment 2.5) - Verify state parameter handling

### üü° Important (Should Fix for MVP) - 6 items
5. **Database separation** (Comment 1.3) - Discuss: 1 vs 2 instances
6. **Idempotency & surge docs** (Comment 1.4) - Cross-ref USAGE_CONTEXT.md
7. **Custom claims overwriting** (Comment 2.7) - Merge claims correctly
8. **Member roster sync** (Comment 2.1) - Document process + future plan
9. **Audit logging** (Comment 2.3) - Add to verifyMembership
10. **Cache-Control headers** (Comment 2.8) - Prevent token caching

### üü¢ Nice to Have (Future) - 8 items
11-18. Code organization, caching, TODOs, error codes, env validation, helpers, cleanup

### üìù Documentation - 3 items
19-21. Member permissions, voting responsibilities, token lifetime

---

## Detailed Review Comments (23 Total)

### 1. Documentation Comments (4)

#### Comment 1.1: Member Permissions Clarification
**File**: `docs/SYSTEM_ARCHITECTURE_OVERVIEW.md`
**Priority**: Minor ("L√≠ti√∞")

**Icelandic**:
> L√≠ti√∞: r√©ttara v√¶ri a√∞ segja a√∞ √æa√∞ s√© h√¶gt a√∞ skilgreina hva√∞a r√©ttindi me√∞limurinn √æarf a√∞ hafa til a√∞ f√° a√∞ taka √æ√°tt e√∞a sj√° kosninguna/atburinn.
>
> Kanski svona:
> Member permission: Which permission(s) (on the user, comes from Members) are required to be allowed to see/vote in an event (election)

**English**:
> Minor: it would be more accurate to say that it's possible to define which permissions the member needs to have in order to participate in or see the election/event.

**Action**:
- [ ] Update `docs/SYSTEM_ARCHITECTURE_OVERVIEW.md` to clarify permission model
- [ ] Emphasize that permissions come from Members service
- [ ] Explain permission requirements for seeing vs voting in elections

---

#### Comment 1.2: Voting System Core Responsibilities
**File**: `docs/SYSTEM_ARCHITECTURE_OVERVIEW.md`
**Priority**: Minor ("L√≠ti√∞")

**Icelandic**:
> L√≠ti√∞: B√¶ta sm√° meira vi√∞ um 3 grunn-√°byr√∞gir kosningakerfisins:
>
> Kanski b√¶ta √æessum atri√∞um vi√∞ (endilega stytta):
> - Ensuring that each user can vote only once.
> - Correct and irreversible consumption of the voting token upon use.
> - Reliable handling of high-concurrency (surge) situations through a queue-based event intake mechanism.

**English**:
> Minor: Add a bit more about the 3 core responsibilities of the voting system:
> - Ensuring that each user can vote only once.
> - Correct and irreversible consumption of the voting token upon use.
> - Reliable handling of high-concurrency (surge) situations through a queue-based event intake mechanism.

**Action**:
- [ ] Update `docs/SYSTEM_ARCHITECTURE_OVERVIEW.md` with 3 core responsibilities
- [ ] Document one-vote-per-user guarantee
- [ ] Document token consumption as irreversible
- [ ] Document queue-based surge handling architecture

**Note**: Already implemented in Phase 5!
- ‚úÖ One vote per token (database UNIQUE constraint)
- ‚úÖ Token marked as `used` (irreversible)
- ‚è∏Ô∏è Queue architecture deferred to Epic #19 (using synchronous for MVP)

---

#### Comment 1.3: Database Separation Recommendation ‚ö†Ô∏è **IMPORTANT**
**File**: `docs/status/CURRENT_PRODUCTION_STATUS.md`
**Priority**: **Important Question**

**Icelandic**:
> V√¶ri betra a√∞ hafa amk 2 db tilvik? V√¶ri ekki best a√∞ amk a√∞greina Me√∞limi & Atbur√∞i fr√° Kosninga-grunninum?

**English**:
> Would it be better to have at least 2 database instances? Wouldn't it be best to at least separate Members & Events from the Elections database?

**Analysis**:
√Åg√∫st suggests **separate database instances** for:
1. **DB Instance 1**: Members + Events (with PII)
2. **DB Instance 2**: Elections (no PII, anonymous ballots)

**Current Setup** (Phase 5):
- **1 database instance**: `ekklesia-db` (db-f1-micro, $7/month)
  - `public` schema: Events service (has PII - kennitala)
  - `elections` schema: Elections service (no PII - token hashes only)
- **Members**: Uses Firestore (not PostgreSQL)

**Pros of Current (1 instance, 2 schemas)**:
- ‚úÖ Cost: $7/month (vs $14/month for 2 instances)
- ‚úÖ Simplicity: One instance to manage
- ‚úÖ Security: Schema-level isolation sufficient for MVP
- ‚úÖ Data separation: Elections schema has zero PII

**Pros of √Åg√∫st's Suggestion (2 instances)**:
- ‚úÖ Stronger isolation: Physical database separation
- ‚úÖ Security: Elections database completely air-gapped from PII
- ‚úÖ Scalability: Independent scaling for high-load Elections service
- ‚úÖ Compliance: Easier to prove anonymity (separate infrastructure)

**Action**:
- [ ] **Discuss with √Åg√∫st**: Is schema-level separation sufficient for MVP?
- [ ] **Security analysis**: Document why schema separation provides adequate anonymity
- [ ] **Future consideration**: Plan for 2nd database instance if needed for load/compliance
- [ ] **Cost/benefit**: $7/month additional cost vs stronger isolation

**Recommendation**:
- **MVP**: Keep current (1 instance, 2 schemas) - cost effective, adequate security
- **Future**: Split to 2 instances if:
  - Load testing shows need for independent scaling
  - Compliance review requires physical separation
  - Budget allows $14/month instead of $7/month

---

#### Comment 1.4: Idempotency & Surge Handling
**File**: `docs/status/CURRENT_PRODUCTION_STATUS.md`
**Priority**: **Important**

**Icelandic**:
> L√≠ti√∞: v√¶ri kanski gott a√∞ minnast √° idempotency og surge virkni h√©r, √æurfum a√∞ hanna √æetta √≠ kringum b√¶√∞i:
> 1) 100% bara einn kosningatoken per kosningu og a√∞ila
> 2) ver√∞ur a√∞ geta h√∂ndla√∞ skyndilegt √°hlaup (200 manns allt √≠ einu), me√∞ t.d. queue arkitekt√∫r - notendur munu √Ωta √° alla takkana √≠ einu ef eitthva√∞ er jafnvel √∂rl√≠ti√∞ seinlegt og √æ√° er gott a√∞ vera me√∞ 100% skilvirk kerfi svo enginn kj√≥si √≥vart 2x e√∞a oftar og l√≠ka bara gera √æetta eins vel hanna√∞ og h√¶gt er til a√∞ taka √° svona √°hlaupum.

**English**:
> Minor: it would maybe be good to mention idempotency and surge handling here, we need to design this around both:
> 1) 100% only one voting token per election and person
> 2) must be able to handle sudden surge (200 people all at once), with e.g. queue architecture - users will press all buttons at once if something is even slightly slow, so it's good to have 100% efficient system so no one votes accidentally 2x or more and also just make this as well designed as possible to handle such surges.

**Action**:
- [ ] Update `docs/status/CURRENT_PRODUCTION_STATUS.md` to document:
  - Idempotency guarantees (one token per member per election)
  - Surge handling architecture (300 votes/sec spike)
  - Database constraints preventing duplicate tokens
  - Transaction-level locking (FOR UPDATE)
- [ ] Add cross-reference to `docs/USAGE_CONTEXT.md` (already has 300 votes/sec analysis)
- [ ] Document future queue architecture (Epic #19 - deferred from MVP)

**Note**: Already extensively documented in Phase 5:
- ‚úÖ `docs/USAGE_CONTEXT.md`: Complete 300 votes/sec surge analysis
- ‚úÖ Database UNIQUE constraints: One token per kennitala
- ‚úÖ Cloud Run scaling: max-instances=100, handles surge
- ‚è∏Ô∏è Queue (Pub/Sub): Deferred to Epic #19 (synchronous sufficient for MVP)

---

### 2. Members Service Implementation (19 comments)

#### Comment 2.1: Member Roster Management ‚ö†Ô∏è **IMPORTANT**
**File**: `members/README.md`
**Priority**: **Important Question**

**Icelandic**:
> Sm√° spurning: hvernig koma kennit√∂lurnar (me√∞limalistinn) inn √≠ kerfi√∞? √âg haf√∞i hugsa√∞ m√©r a√∞ "Me√∞limir" kerfi√∞ yr√∞i bara hin eina sanna me√∞limaskr√° en √©g held a√∞ √æa√∞ s√© kanski ekki alveg raunh√¶ft til a√∞ byrja me√∞ √æv√≠ eldra kerfi√∞ sem √æau nota b√Ω√∞ur upp √° √∫tsendigar √° p√≥stum og √æannig.

**English**:
> Small question: how do the kennitala (member list) get into the system? I had imagined that the "Members" system would be the one true member registry but I think that might not be quite realistic to start with because the old system they use offers mailing lists and such.

**Analysis**:
- **Current**: Manual upload to Firebase Storage (`kennitalas.txt`, 2,273 members)
- **√Åg√∫st's vision**: Members system as "single source of truth"
- **Reality**: Legacy system has needed features (mailing lists, etc.)

**Action**:
- [ ] Document current approach in `members/README.md`
- [ ] Create sync plan for future (API import, admin UI, etc.)
- [ ] Discuss with √Åg√∫st: When can Members become "single source of truth"?

**Current Process** (needs documentation):
```bash
# 1. Export from legacy system (monthly)
# 2. Convert to kennitalas.txt (one kennitala per line)
# 3. Upload to Firebase Storage
gsutil cp kennitalas.txt gs://ekklesia-prod-10-2025.firebasestorage.app/
```

---

#### Comment 2.2: Custom Token Lifetime Control
**File**: `members/README.md`
**Priority**: Minor

**Icelandic**: > Er h√¶gt a√∞ stj√≥rna hversu lengi √æessir tokenar lifa?
**English**: > Is it possible to control how long these tokens live?

**Answer**: Yes! Firebase custom tokens have configurable expiration.

**Action**:
- [ ] Document token lifetime in `members/README.md`
- [ ] Add configuration example (default: 1 hour)
- [ ] Consider shorter expiration for security (e.g., 30 minutes)

---

#### Comment 2.3: Audit Logging for Membership Verification
**File**: `members/README.md`
**Priority**: Important

**Icelandic**:
> L√≠ti√∞: v√¶ri sennilega gott a√∞ audit logga √æetta, amk √æegar √æetta er gert √≠ tengslum vi√∞ kosningu til a√∞ auka √°rei√∞anleika

**English**:
> Minor: it would probably be good to audit log this, at least when done in connection with elections to increase reliability

**Action**:
- [ ] Add audit logging to `verifyMembership` Cloud Function
- [ ] Log: timestamp, kennitala prefix (masked), result, context
- [ ] Use Cloud Logging structured logs (JSON)
- [ ] Document in `members/README.md`

---

#### Comment 2.4: Firestore Security Rules üî¥ **CRITICAL**
**File**: `members/README.md`
**Priority**: **Critical**

**Icelandic**:
> √ûa√∞ er h√¶gt a√∞ gera allskonar sni√∞uga hluti me√∞ FB reglunum - en √≠ grunninn er √æa√∞ mikilv√¶gasta a√∞ notendur geti bara s√©√∞ uppl√Ωsingar sem √æeir mega sj√°, t.d. aldrei uppl√Ωsingar um a√∞ra notendur (nema hafa r√©ttindi)

**English**:
> It's possible to do all sorts of clever things with Firebase rules - but basically the most important thing is that users can only see information they're allowed to see, e.g. never information about other users (unless they have permissions)

**Action**:
- [ ] Review current Firestore security rules (`firestore.rules`)
- [ ] Ensure users can only read their own profile
- [ ] Ensure users cannot read other users' profiles
- [ ] Test rules with Firebase Emulator before deploying
- [ ] Document in `members/README.md`

**Example Rules**:
```javascript
rules_version = '2';
service cloud.firestore {
  match /databases/{database}/documents {
    match /users/{userId} {
      // User can only read their own document
      allow read: if request.auth != null && request.auth.uid == userId;

      // User can update own document (limited fields)
      allow update: if request.auth != null
                    && request.auth.uid == userId
                    && !request.resource.data.diff(resource.data).affectedKeys()
                       .hasAny(['kennitala', 'isMember', 'uid']);

      // Only server (Cloud Functions) can create/delete
      allow create, delete: if false;
    }
  }
}
```

---

#### Comment 2.5: CSRF Protection (State/Nonce) üî¥ **CRITICAL**
**File**: `members/functions/main.py`
**Priority**: **Security Critical**

**Icelandic**: > √ûarf a√∞ gera meiri nonce og state (CSRF) t√©kk h√©r?
**English**: > Do we need to do more nonce and state (CSRF) checks here?

**Action**:
- [ ] Verify state parameter validation in `handle_kenni_auth`
- [ ] Ensure state is stored in session before OAuth redirect
- [ ] Ensure state is validated when callback returns
- [ ] Ensure state is single-use (prevents replay)
- [ ] Add nonce to ID token validation (if using OIDC)
- [ ] Document CSRF protection in code comments

**Note**: PKCE already provides strong CSRF protection, but state parameter is defense-in-depth.

---

#### Comment 2.6: Client Secret with PKCE
**File**: `members/functions/main.py`
**Priority**: Security Question

**Icelandic**: > √ûurfum vi√∞ client_secret ef kenni sty√∞ur public+PKCE?
**English**: > Do we need client_secret if Kenni supports public+PKCE?

**Action**:
- [ ] Verify with Kenni.is: Do they require client_secret even with PKCE?
- [ ] If not required: Remove client_secret, update to "public client"
- [ ] If required: Document why (Kenni.is policy)

**Note**: Many OIDC providers support PKCE without client_secret for better security.

---

#### Comment 2.7: Custom Claims Overwriting
**File**: `members/functions/main.py`
**Priority**: **Bug Risk**

**Icelandic**: > Yfirskrifar √æetta custom_claims sem voru sett √≠ handleKenniAuth (email og s√≠mi)?
**English**: > Does this overwrite the custom_claims that were set in handleKenniAuth (email and phone)?

**Action**:
- [ ] Review claim setting logic
- [ ] Fix if overwriting - merge claims instead:

```python
# Get existing claims
user = auth.get_user(uid)
existing_claims = user.custom_claims or {}

# Merge new claims
new_claims = {**existing_claims, 'isMember': is_member}

# Set merged claims
auth.set_custom_user_claims(uid, new_claims)
```

---

#### Comment 2.8: Cache-Control Header for Tokens
**File**: `members/functions/main.py`
**Priority**: Security Enhancement

**Icelandic**: > V√¶ri gott a√∞ b√¶ta vi√∞ Cache-Control: no-store svo tokeninn s√© ekki cache-a√∞ur √° client
**English**: > Would be good to add Cache-Control: no-store so the token is not cached on client

**Action**:
- [ ] Add Cache-Control header to token response:

```python
response = jsonify({'token': custom_token, 'uid': uid})
response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, private'
response.headers['Pragma'] = 'no-cache'
return response
```

---

#### Comment 2.9: Membership List Caching
**File**: `members/functions/main.py`
**Priority**: Performance (Future)

**Icelandic**: > Mun √æetta fall ver√∞a a√∞ fl√∂skuh√°lsi √æegar √æa√∞ er √°hlaup? Ef svo, kanski b√¶ta vi√∞ skamml√≠fu cache (√≠ minni)
**English**: > Will this function become a bottleneck when there's a surge? If so, maybe add short-lived cache (in memory)

**Analysis**:
- Current: Reads `kennitalas.txt` from Firebase Storage on every call
- Peak load: 20 logins/minute during meeting start
- **Not a bottleneck** for MVP

**Action** (Future Optimization):
- [ ] For MVP: No caching needed (low traffic)
- [ ] Future (if >100 req/min): Add in-memory cache with 5-minute TTL

---

#### Comment 2.10: Race Condition on User Creation üî¥ **CRITICAL**
**File**: `members/functions/main.py`
**Priority**: **Bug Risk - Critical**

**Icelandic**:
> Ef 2 (e√∞a fleiri) bei√∞nir koma fr√° client fyrir sama notanda √æ√° er h√¶tta √° a√∞ √æa√∞ skr√°ist 2x sami a√∞ili (af √æv√≠ vi√∞ √æurfum a√∞ b√≠√∞a eftir a√∞ Firebase segi okkur hvort notandinn s√© til e√∞a ekki) - getum vi√∞ gert eitthva√∞ til a√∞ fyrirbyggja √æa√∞ a√∞ sami notandi skr√°ist tvisvar, √≠ √∂llum tilfellum?

**English**:
> If 2 (or more) requests come from client for the same user, there's a risk that the same person gets registered 2x (because we need to wait for Firebase to tell us if the user exists or not) - can we do something to prevent the same user from being registered twice, in all cases?

**Race Condition Scenario**:
```
Request A: Check if user exists ‚Üí No ‚Üí Create user
Request B: Check if user exists ‚Üí No ‚Üí Create user (race!)
```

**Action** - Implement idempotency:

**Option 1: Use kennitala as Firebase UID** (Recommended):
```python
# Use kennitala hash as deterministic UID
uid = hashlib.sha256(kennitala.encode()).hexdigest()[:28]

try:
    user = auth.create_user(
        uid=uid,  # Deterministic UID prevents duplicates
        email=email,
        display_name=display_name
    )
except auth.UidAlreadyExistsError:
    # User already exists - this is OK (idempotent)
    user = auth.get_user(uid)
```

**Option 2: Firestore transaction with kennitala document** (see full code in detailed review)

- [ ] Implement one of the above options
- [ ] Add retry logic for transient failures
- [ ] Test with concurrent requests (load test)

---

#### Comment 2.11: Membership List Update TODO
**File**: `members/functions/main.py`
**Priority**: Future Work

**Icelandic**: > V√¶ri gott a√∞ setja // TODO og verkefni √° √æetta - viljum sennilega ekki vera a√∞ v√≠sa √≠ static txt skr√° sem er flj√≥tt √∫reld
**English**: > Would be good to add // TODO and task on this - we probably don't want to be referencing a static txt file that quickly becomes outdated

**Action**:
- [ ] Add TODO comment in code
- [ ] Create GitHub issue for membership roster synchronization
- [ ] Link to √Åg√∫st's comment about "single source of truth"

---

#### Comment 2.12: Domain Redirect URL TODO
**File**: `members/functions/main.py`
**Priority**: Pre-Production Task

**Icelandic**: > G√¶tir√∞u sett // TODO og v√≠sun √≠ Task um a√∞ uppf√¶ra √æetta √°√∞ur en vi√∞ f√∂rum √∫t me√∞ lausnina √æannig a√∞ √æa√∞ v√≠si √° okkar domain
**English**: > Could you add // TODO and reference to Task about updating this before we go out with the solution so it points to our domain

**Action**:
- [ ] Add TODO comment about production domain
- [ ] Create task: "Configure production domain and update OAuth redirect_uri"
- [ ] Document domain setup steps in deployment guide

---

#### Comment 2.13: Error Code 4xx vs 500
**File**: `members/functions/main.py`
**Priority**: Code Quality

**Icelandic**: > √ûetta er sennilega frekar einhver 4xx villa frekar en 500
**English**: > This is probably more like a 4xx error rather than 500

**Action**:
- [ ] Review error handling - use appropriate HTTP status codes:
  - `400 Bad Request`: Invalid input
  - `401 Unauthorized`: Authentication failed
  - `403 Forbidden`: Valid auth but not allowed
  - `404 Not Found`: Resource doesn't exist
  - `409 Conflict`: Duplicate resource
  - `429 Too Many Requests`: Rate limit exceeded
  - `500 Internal Server Error`: Unexpected server error only

---

#### Comment 2.14: Environment Variable Validation
**File**: `members/functions/main.py`
**Priority**: Fail-Fast

**Icelandic**: > Verum viss um a√∞ √æetta v√≠si √≠ r√©tt env gildi - og fail-fast ef √æa√∞ er rangt me√∞ sk√Ωrri villu
**English**: > Make sure this points to correct env value - and fail-fast if it's wrong with clear error

**Action**:
- [ ] Add environment variable validation at function startup
- [ ] Validate required env vars exist
- [ ] Validate format (e.g., URLs must be HTTPS)
- [ ] Add startup logging

---

#### Comment 2.15: Use normalize_kennitala Helper
**File**: `members/functions/main.py`
**Priority**: Code Quality

**Icelandic**: > Notum normalize_kennitala falli√∞
**English**: > Use the normalize_kennitala function

**Action**:
- [ ] Ensure `normalize_kennitala()` helper is used consistently everywhere
- [ ] Grep for kennitala handling and ensure normalization used

---

#### Comment 2.16 & 2.17: Rate Limiting üî¥ **CRITICAL** (Duplicate Comments)
**File**: `members/functions/main.py`
**Priority**: **Security - DDoS Protection**

**Icelandic**: > B√¶ta vi√∞ rate-limit virkni √æannig a√∞ √æa√∞ s√© ekki h√¶gt a√∞ drepa okkur (eins au√∞veldlega)?
**English**: > Add rate-limit functionality so it's not possible to kill us (as easily)?

**Action**:
- [ ] Implement rate limiting for Cloud Functions
- [ ] Option 1: Cloud Armor (GCP built-in) - Recommended
- [ ] Option 2: Application-level (Firestore-based)
- [ ] Document rate limits in API documentation
- [ ] Set conservative limits for MVP (100 req/min per IP)

---

#### Comment 2.18: Code Organization - Split main.py
**File**: `members/functions/main.py`
**Priority**: Code Quality / Maintainability

**Icelandic**: > Kannski v√¶ri sk√Ωrara a√∞ skipta main.py upp √≠ nokkrar minni skr√°r t.d. helpers.py fyrir hj√°lparf√∂ll, auth_flow.py fyrir innskr√°ningarfl√¶√∞i og membership.py fyrir me√∞limapr√≥fanir.
**English**: > Maybe it would be clearer to split main.py into several smaller files, e.g. helpers.py for helper functions, auth_flow.py for login flow and membership.py for membership checks.

**Action**:
- [ ] Refactor `members/functions/` directory structure:

**Proposed Structure**:
```
members/functions/
‚îú‚îÄ‚îÄ main.py              # Entry point only (Flask app + routes)
‚îú‚îÄ‚îÄ auth_flow.py         # OAuth flow (handleKenniAuth logic)
‚îú‚îÄ‚îÄ membership.py        # Membership verification (verifyMembership logic)
‚îú‚îÄ‚îÄ helpers.py           # Shared utilities
‚îú‚îÄ‚îÄ config.py            # Environment variable loading & validation
‚îî‚îÄ‚îÄ requirements.txt
```

---

#### Comment 2.19: Move server.js to tools/
**File**: `members/server.js`
**Priority**: Code Cleanup

**Icelandic**: > √ûessi skr√° er vir√∞ist ekki vera notu√∞ fyrir vefs√≠√∞una sem almenningur s√©r (Firebase Hosting h√Ωsir a√∞eins stat√≠skar skr√°r). Kanski betra a√∞ f√¶ra hana √≠ tools/ e√∞a √°l√≠ka m√∂ppu?
**English**: > This file doesn't seem to be used for the website that the public sees (Firebase Hosting only hosts static files). Maybe better to move it to tools/ or similar folder?

**Action**:
- [ ] Move `members/server.js` to `members/tools/local-dev-server.js`
- [ ] Update `members/README.md` documentation
- [ ] Add comment explaining it's for local development only

---

## Action Plan by Phase

### Phase 1: Critical Fixes (Before Merging PR #28)
- [ ] Implement user creation idempotency (Comment 2.10) üî¥
- [ ] Review and document Firestore security rules (Comment 2.4) üî¥
- [ ] Verify CSRF protection (state parameter) (Comment 2.5) üî¥
- [ ] Add basic rate limiting (Comments 2.16, 2.17) üî¥

### Phase 2: Important Updates (Before First Production Meeting)
- [ ] Discuss database separation with √Åg√∫st (Comment 1.3)
- [ ] Update documentation with idempotency & surge (Comment 1.4)
- [ ] Fix custom claims merging (Comment 2.7)
- [ ] Add audit logging (Comment 2.3)
- [ ] Add Cache-Control headers (Comment 2.8)
- [ ] Document member roster sync process (Comment 2.1)

### Phase 3: Code Quality (Post-MVP)
- [ ] Refactor main.py into modules (Comment 2.18)
- [ ] Add all TODOs to code (Comments 2.11, 2.12)
- [ ] Fix error codes (Comment 2.13)
- [ ] Add environment validation (Comment 2.14)
- [ ] Ensure normalize_kennitala used everywhere (Comment 2.15)
- [ ] Move server.js to tools/ (Comment 2.19)

### Phase 4: Documentation Updates (Post-PR-Merge)
- [ ] Update SYSTEM_ARCHITECTURE_OVERVIEW.md (Comments 1.1, 1.2)
- [ ] Document token lifetime control (Comment 2.2)
- [ ] Update all technical documentation with Phase 1-2 changes

---

## Discussion Topics for √Åg√∫st

### Question 1: Database Separation
**Context**: Comment 1.3
**Question**: Is schema-level separation (1 instance, 2 schemas) sufficient for MVP, or do we need 2 separate database instances for stronger isolation?
- Current: $7/month (1 instance)
- Proposed: $14/month (2 instances)
- Trade-off: Cost vs stronger security isolation

### Question 2: Client Secret with PKCE
**Context**: Comment 2.6
**Question**: Does Kenni.is support public client PKCE (without client_secret), or is client_secret required even with PKCE?
- Impact: Could remove `kenni-client-secret` from Secret Manager if not needed

### Question 3: Membership Roster Sync
**Context**: Comment 2.1
**Question**: Timeline for Members system becoming "single source of truth"? Until then, what's preferred sync method?
- Option A: Continue manual CSV upload
- Option B: Build API import from legacy system
- Option C: Build admin UI for roster management

---

## GitHub Issues to Create

1. [ ] "Implement user creation idempotency to prevent race conditions" üî¥
2. [ ] "Add rate limiting to Cloud Functions" üî¥
3. [ ] "Review and document Firestore security rules" üî¥
4. [ ] "Verify CSRF protection (state/nonce validation)" üî¥
5. [ ] "Add audit logging for membership verification"
6. [ ] "Refactor members/functions/main.py into modules"
7. [ ] "Document membership roster synchronization process"
8. [ ] "Discuss: Database separation strategy (1 vs 2 instances)"

---

## Immediate Actions (Before Merge)

### For PR #28 Merge:
- [ ] Copy squash commit message from `PR28_SQUASH_COMMIT_MESSAGE.md`
- [ ] Click "Squash and merge" button on PR #28
- [ ] Paste comprehensive commit message into GitHub editor
- [ ] Confirm squash and merge
- [ ] Verify merge commit appears on main branch
- [ ] Delete `feature/firebase-members-auth` branch

### Post-Merge Actions:
- [ ] Verify PR #28 automatically closes linked issues (#16, #20, #22)
- [ ] Update project board (move cards to "Done")
- [ ] Pull latest main branch: `git checkout main && git pull origin main`
- [ ] Create GitHub issues for critical fixes (4 critical items)
- [ ] Announce Members service production launch to team

---

## Phase 5 Considerations

### Current State:
- PR #28 approved (Members service)
- Phase 5 branch exists (`feature/elections-design-and-ops-docs`)
- Phase 5 includes:
  - Events service implementation (5 commits)
  - Elections service implementation (complete)
  - Full S2S integration (Events ‚Üî Elections)
  - Test interface (voting UI)
  - Comprehensive documentation

### Decision Needed:
**Should Phase 5 branch be merged as-is, or split into separate PRs?**

Ask √Åg√∫st:
> "PR #28 er sameina√∞! üéâ N√∫na er Phase 5 tilb√∫i√∞ (Events + Elections full integration).
> Viltu a√∞ √©g b√∫i til einn st√≥ran PR fyrir Phase 5, e√∞a skipti √æv√≠ √≠ tvo PRa (Events s√©r og Elections s√©r)?
> Phase 5 branch er tilb√∫inn me√∞ √∂llu - b√¶√∞i services eru deployed og tested."

**Translation**:
> "PR #28 is merged! üéâ Now Phase 5 is ready (Events + Elections full integration).
> Do you want me to create one big PR for Phase 5, or split it into two PRs (Events separate and Elections separate)?
> Phase 5 branch is ready with everything - both services are deployed and tested."

---

## Related Documentation

- **Original PR #28**: https://github.com/sosialistaflokkurinn/ekklesia/pull/28
- **PR #28 Squash Commit Message**: [PR28_SQUASH_COMMIT_MESSAGE.md](../../PR28_SQUASH_COMMIT_MESSAGE.md)
- **Branch Strategy**: [docs/guides/BRANCH_STRATEGY.md](../guides/BRANCH_STRATEGY.md)
- **Phase 5 Complete**: [docs/status/PHASE_5_INTEGRATION_COMPLETE.md](PHASE_5_INTEGRATION_COMPLETE.md)
- **Production Status**: [docs/status/CURRENT_PRODUCTION_STATUS.md](CURRENT_PRODUCTION_STATUS.md)
- **Usage Context (300 votes/sec)**: [docs/USAGE_CONTEXT.md](../USAGE_CONTEXT.md)

---

## Timeline

- **October 8, 2025**: PR #28 created (68 commits)
- **October 10, 2025 06:53 UTC**: √Åg√∫st approves PR #28 ‚úÖ
- **October 10, 2025 09:00+ UTC**: Awaiting squash merge
- **Next**: Pull main, proceed with Phase 5 PRs

---

**Status**: ‚úÖ APPROVED (with suggested improvements)
**Total Comments**: 23 detailed review comments + 1 overall approval
**Reviewer**: @agustka (√Åg√∫st K√°rason)
**Review Date**: October 10, 2025 06:53 UTC
**Action Required**: Merge PR #28, then address critical fixes (4 items) before first production meeting
